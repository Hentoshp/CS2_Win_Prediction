{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7d0c41a0-4ac2-4ff8-927e-3168dfee05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import nbimporter\n",
    "from win_prediction_functions import get_player_data, get_player_stats, player_stats_calc, calculate_match_stats\n",
    "from auth_key import get_auth_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2763674b-5a58-45e8-85ad-201b84110be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_key = get_auth_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "db1e0c29-f23b-4244-810c-06197329a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_player_data(team_a_nicknames, team_b_nicknames, map, auth_key):\n",
    "\n",
    "    # creating columns for new data frame\n",
    "    columns = [\"map\", \"Team_A_avg_win_percentage\", \"Team_A_avg_KR\", \"Team_A_avg_elo\",\n",
    "                  \"Team_B_avg_win_percentage\", \"Team_B_avg_KR\", \"Team_B_avg_elo\"]\n",
    "    \n",
    "    # creating match data frame\n",
    "    \n",
    "    data_df = pd.DataFrame(columns = columns)\n",
    "    data_df.columns\n",
    "\n",
    "    # assigning none to Win row and assigning map\n",
    "    data_df.loc[0, \"map\"] = map\n",
    "\n",
    "    # Team A Stats\n",
    "    team_a_id_elo_list = []\n",
    "\n",
    "    # loops over nicknames column and appends list of player ids for team A\n",
    "    for nickname in team_a_nicknames:\n",
    "        id_elo = get_player_data(nickname, auth_key)\n",
    "        \n",
    "        # returns empty dataframe if player elo DNE\n",
    "        if id_elo.empty:\n",
    "            return id_elo\n",
    "        else:\n",
    "            team_a_id_elo_list.append(id_elo)\n",
    "\n",
    "    # creates column of player IDs from list\n",
    "    team_a_id_elo_df = pd.concat(team_a_id_elo_list)\n",
    "\n",
    "    # adds mean of team elo to match data df\n",
    "    data_df.loc[0 , \"Team_A_avg_elo\"] = team_a_id_elo_df[\"faceit_elo\"].mean()\n",
    "    \n",
    "    # Uses player ID to calculate individual player stats (K/R and win percentage)\n",
    "    team_a_stats_list = []\n",
    "    \n",
    "    for id in team_a_id_elo_df.player_id:\n",
    "        # uses get_player_stats to calculate individual stats\n",
    "        stats_df = get_player_stats(id, auth_key)\n",
    "        stats = player_stats_calc(stats_df, data_df[\"map\"][0])\n",
    "        \n",
    "        # if returned df is empty, return empty match dataframe\n",
    "        if stats.empty:\n",
    "            print(\"Unable to compute stats, may be error with map used\")\n",
    "            return stats\n",
    "\n",
    "        # append individual stats to list\n",
    "        else: \n",
    "            team_a_stats_list.append(stats)\n",
    "\n",
    "    # creates win percentage and K/R ratio columns for team A \n",
    "    team_a_stats_df = pd.concat(team_a_stats_list)\n",
    "    data_df.loc[0 , \"Team_A_avg_win_percentage\"] = team_a_stats_df[\"Win Percentage\"].mean()\n",
    "    data_df.loc[0 , \"Team_A_avg_KR\"] = team_a_stats_df[\"Average K/R Ratio\"].mean()\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Team B stats, repeats same process used for team A stats\n",
    "    team_b_id_elo_list = []\n",
    "    \n",
    "    for nickname in team_b_nicknames:\n",
    "        \n",
    "        if id_elo.empty:\n",
    "            return id_elo\n",
    "            \n",
    "        else:\n",
    "            team_b_id_elo_list.append(id_elo)\n",
    "    \n",
    "    team_b_id_elo_df = pd.concat(team_b_id_elo_list)\n",
    "    team_b_id_elo_df\n",
    "    data_df.loc[0 , \"Team_B_avg_elo\"] = team_b_id_elo_df[\"faceit_elo\"].mean()\n",
    "    \n",
    "    \n",
    "    team_b_stats_list = []\n",
    "    for id in team_b_id_elo_df.player_id:\n",
    "        \n",
    "        stats_df = get_player_stats(id, auth_key)\n",
    "        stats = player_stats_calc(stats_df, data_df[\"map\"][0])\n",
    "        \n",
    "        if stats.empty:\n",
    "            print(\"Unable to compute stats, may be error with map used\")\n",
    "            return stats\n",
    "            \n",
    "        else: \n",
    "            team_b_stats_list.append(stats)\n",
    "            \n",
    "    team_b_stats_df = pd.concat(team_b_stats_list)\n",
    "    data_df.loc[0 , \"Team_B_avg_win_percentage\"] = team_b_stats_df[\"Win Percentage\"].mean()\n",
    "    data_df.loc[0 , \"Team_B_avg_KR\"] = team_b_stats_df[\"Average K/R Ratio\"].mean()\n",
    "\n",
    "    # Returns row of match data for match_id given\n",
    "    data_df.drop(columns = ['map'], inplace = True)\n",
    "    return data_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "21456a0c-0f1f-4fd5-855e-f23e5ba7423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes user input and returns list of team_nicknames and map name\n",
    "def team_inputs():\n",
    "    # loops over range and takes input for team A player nicknames\n",
    "    team_a_nicknames = []\n",
    "    for i in range(1, 6):\n",
    "        nickname = input(f\"Team A nickname {i}:\", )\n",
    "        team_a_nicknames.append(nickname)\n",
    "    # repeats for team b\n",
    "    team_b_nicknames = []\n",
    "    for i in range(1, 6):\n",
    "        nickname = input(f\"Team B nickname {i}:\", )\n",
    "        team_b_nicknames.append(nickname)\n",
    "\n",
    "    map = input(\"Map: \",)\n",
    "\n",
    "    # returns team_a, team_b nicknames and map name\n",
    "    return team_a_nicknames, team_b_nicknames, map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "72e2d925-5454-435b-9de3-a5c01823716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates win probability given model \n",
    "def win_probability_calc(model, auth_key):\n",
    "    # using team_inputs and new_player_data func to get player data\n",
    "    team_a, team_b, map = team_inputs()\n",
    "    new_data = new_player_data(team_a, \n",
    "                               team_b, \n",
    "                               map, \n",
    "                               auth_key)\n",
    "\n",
    "    # finding probability given model\n",
    "    win_prob = model.predict_proba(new_data)\n",
    "\n",
    "    return win_prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "24388f30-3fd2-4879-a9c2-4e1ad1d82bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling code from fit and tuning file and fitting a logistic regression model\n",
    "\n",
    "# readining in win prediction data\n",
    "data = pd.read_excel(\"data_win_prediction.xlsx\")\n",
    "data.columns = [\"win\", \"map\", \n",
    "                \"Team_A_avg_win_percentage\", \n",
    "                \"Team_A_avg_KR\", \"Team_A_avg_elo\", \n",
    "                \"Team_B_avg_win_percentage\", \n",
    "                \"Team_B_avg_KR\", \"Team_B_avg_elo\", \n",
    "                \"Match ID\"]\n",
    "\n",
    "# checking for missing data\n",
    "data.isna().sum()\n",
    "\n",
    "# checking for duplicated rows\n",
    "data.duplicated().sum()\n",
    "\n",
    "# removing duplicated rows\n",
    "data = data.drop_duplicates()\n",
    "data.duplicated().sum()\n",
    "\n",
    "# spliting features and response variable\n",
    "features = data.loc[:, [\"Team_A_avg_win_percentage\", \"Team_A_avg_KR\", \"Team_A_avg_elo\",\n",
    "                  \"Team_B_avg_win_percentage\", \"Team_B_avg_KR\", \"Team_B_avg_elo\"]]\n",
    "# transforming response column into a 1d array\n",
    "response = data.loc[:, [\"win\"]].values.ravel()\n",
    "\n",
    "# Importing required models for logistic regession\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# fitting the regression model\n",
    "lr_model = LogisticRegression(max_iter = 200)\n",
    "\n",
    "# splitting data into k folds\n",
    "folds = KFold(n_splits = 10, shuffle = True, random_state = 50)\n",
    "\n",
    "# Perform k-folds cross validation\n",
    "scores = cross_val_score(lr_model, features, response, cv = folds, scoring = 'accuracy')\n",
    "scores.mean()\n",
    "\n",
    "# fitting model \n",
    "fit_model = lr_model.fit(features, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b47f54b-fc14-40d9-bda7-2595181bbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_a_nicknames  = [\"pratesz\", \"tommyy_24\", \"marchyswag\", \"-Phe0nix\", \"Qestane\"]\n",
    "team_b_nicknames = [\"Frimzon\", \"DomSJ\", \"WOAH234\", \"Gemini-JC\", \"Cal1B0yz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ac52bae-8d8d-4bd3-b6c5-1f1467c2b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = lr_model.fit(features, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "749468b2-09ca-4b82-8e2b-fd4b3eee9b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Team A nickname 1: \n",
      "Team A nickname 2: \n",
      "Team A nickname 3: \n",
      "Team A nickname 4: \n",
      "Team A nickname 5: \n",
      "Team B nickname 1: \n",
      "Team B nickname 2: \n",
      "Team B nickname 3: \n",
      "Team B nickname 4: \n",
      "Team B nickname 5: \n",
      "Map:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 400: {\"errors\":[{\"message\":\"You must specify a 'nickname' parameter or 'game' and 'game_player_id' parameters\",\"code\":\"err_br0\",\"http_status\":400,\"parameters\":[]}]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m win_probability_calc(fit_model, auth_key)\n",
      "Cell \u001b[0;32mIn[173], line 11\u001b[0m, in \u001b[0;36mwin_probability_calc\u001b[0;34m(model, auth_key)\u001b[0m\n\u001b[1;32m      5\u001b[0m new_data \u001b[38;5;241m=\u001b[39m new_player_data(team_a, \n\u001b[1;32m      6\u001b[0m                            team_b, \n\u001b[1;32m      7\u001b[0m                            \u001b[38;5;28mmap\u001b[39m, \n\u001b[1;32m      8\u001b[0m                            auth_key)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# finding probability given model\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m win_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(new_data)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m win_prob\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1377\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1369\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     )\n\u001b[1;32m   1375\u001b[0m )\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_predict_proba_lr(X)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_base.py:366\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[1;32m    367\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    877\u001b[0m )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    882\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "win_probability_calc(fit_model, auth_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee90be50-42e3-4291-9f0d-5502aa0bc806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e482a94-233c-4848-aeb5-e26ccf7f582a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
